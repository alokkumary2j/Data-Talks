{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imputeDFColsUsingMedian(dataFrame,cols):\n",
    "    for col in cols:\n",
    "        medianOfCol=np.nanmedian(dataFrame[col])\n",
    "        dataFrame[col].fillna(medianOfCol,inplace=True)\n",
    "def imputeDFColsUsingMean(dataFrame,cols):\n",
    "    for col in cols:\n",
    "        meanOfCol=np.nanmean(dataFrame[col])\n",
    "        dataFrame[col].fillna(meanOfCol,inplace=True)\n",
    "def scaleFeature(dataFrame,col):\n",
    "    maxVal=np.max(dataFrame[col])\n",
    "    minVal=np.min(dataFrame[col])\n",
    "    scaledDenom=maxVal-minVal\n",
    "    dataFrame[col]=(dataFrame[col]-minVal)/scaledDenom\n",
    "def labelEncodeFeats(dataFrame,listOfFeats):\n",
    "    for feat in listOfFeats:\n",
    "        labelEncoder=LabelEncoder()\n",
    "        encodedFeatValues=labelEncoder.fit_transform(dataFrame[feat])\n",
    "        dataFrame[feat]=encodedFeatValues\n",
    "def OneHotEncodeFeats(dataFrame,listOfFeats,ctgrcl_ftrs_msk):\n",
    "    labelEncodeFeats(dataFrame,listOfFeats)\n",
    "    oneHotEncoder=OneHotEncoder(categorical_features=ctgrcl_ftrs_msk,sparse=False)\n",
    "    oneHotEncodedFeats=oneHotEncoder.fit_transform(dataFrame)\n",
    "    return oneHotEncodedFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_events = pd.read_csv('../Data/app_events.csv')\n",
    "app_labels = pd.read_csv('../Data/app_labels.csv')\n",
    "events = pd.read_csv('../Data/events.csv')\n",
    "events.timestamp=events.timestamp.map(lambda x:pd.Timestamp(x).value)\n",
    "eventsGrpdByDeviceId=events.groupby('device_id')\n",
    "gender_age_train = pd.read_csv('../Data/gender_age_train.csv')\n",
    "gender_age_test = pd.read_csv('../Data/gender_age_test.csv')\n",
    "label_categories = pd.read_csv('../Data/label_categories.csv')\n",
    "phone_brand_device_model = pd.read_csv('../Data/phone_brand_device_model.csv',encoding='utf-8')\n",
    "phone_brand_device_model = phone_brand_device_model.drop_duplicates('device_id',keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joinBrandDeviceModel(deviceIDFrame,brandDeviceModelFrame):\n",
    "    mergedDF=deviceIDFrame.merge(brandDeviceModelFrame[['device_id','phone_brand','device_model']], \n",
    "                                 how='left',on='device_id')\n",
    "    mergedDF['phone_brand'].fillna('',inplace=True)\n",
    "    mergedDF['device_model'].fillna('',inplace=True)\n",
    "    return mergedDF\n",
    "device_brand_model_trainDF=joinBrandDeviceModel(gender_age_train,phone_brand_device_model)\n",
    "device_brand_model_testDF=joinBrandDeviceModel(gender_age_test,phone_brand_device_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avgEventDuration(listOfTimeStamps):\n",
    "    if(len(listOfTimeStamps)<1):\n",
    "        return 0\n",
    "    return (np.max(listOfTimeStamps)-np.min(listOfTimeStamps))/len(listOfTimeStamps)\n",
    "def stdEventDuration(listOfTimeStamps):\n",
    "    if(len(set(listOfTimeStamps))<=1):\n",
    "        return 0\n",
    "    return np.std(listOfTimeStamps)\n",
    "def avglongChangeFreq(listOfLongs):\n",
    "    if(len(listOfLongs)<1):\n",
    "        return 0\n",
    "    return len(set(listOfLongs))/float(len(listOfLongs))\n",
    "def avgSqrdlongChangeAmt(listOfLongs):\n",
    "    if(len(listOfLongs)<1):\n",
    "        return 0\n",
    "    return np.sum(np.diff(listOfLongs)**2)/float(len(listOfLongs))\n",
    "def computeEventBasedFeatures(eventsGrpdByDeviceId):\n",
    "    eventBasedAggregates=eventsGrpdByDeviceId.aggregate({'timestamp':[np.count_nonzero,avgEventDuration,\n",
    "                            stdEventDuration],'longitude':[avglongChangeFreq,avgSqrdlongChangeAmt]})\n",
    "    eventBasedAggregatesFeats=['num_of_evnts','avg_evnt_drtn','std_evnt_drtn','avgLongtdChgFrq','avgSqrdLongtdChgAmt']\n",
    "    eventBasedAggregates.columns=eventBasedAggregatesFeats\n",
    "    eventBasedAggregates['device_id']=eventBasedAggregates.index\n",
    "    return (eventBasedAggregates,eventBasedAggregatesFeats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(eventBasedFeaturesDF,eventBasedFeats)=computeEventBasedFeatures(eventsGrpdByDeviceId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combineDeviceEventsBrandsFeatures(deviceDF,deviceEventsDF,deviceEventsFeats,deviceBrandsDF):\n",
    "    device_events_brands =deviceDF.merge(deviceEventsDF, how='left',on='device_id')\n",
    "    imputeDFColsUsingMean(device_events_brands,deviceEventsFeats)\n",
    "    device_events_brands=device_events_brands.merge(deviceBrandsDF[['phone_brand','device_model','device_id']], \n",
    "                                                  how='left',on='device_id')\n",
    "    return device_events_brands\n",
    "deviceEvntsBrnds_trainDF=combineDeviceEventsBrandsFeatures(gender_age_train,eventBasedFeaturesDF,\n",
    "                                                   eventBasedFeats,device_brand_model_trainDF)\n",
    "deviceEvntsBrnds_testDF=combineDeviceEventsBrandsFeatures(gender_age_test,eventBasedFeaturesDF,\n",
    "                                                   eventBasedFeats,device_brand_model_testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def processModelFeatures(contFeats,catFeats,modelDF,categorical_features_mask):\n",
    "    contFeats=list(set(contFeats))\n",
    "    catFeats=list(set(catFeats))\n",
    "    modelFeatures=contFeats.copy()\n",
    "    modelFeatures.extend(catFeats)\n",
    "    model_subsetDF=modelDF[modelFeatures]\n",
    "    for contFeat in contFeats:\n",
    "        scaleFeature(model_subsetDF,contFeat)\n",
    "    processedModelFeatures=OneHotEncodeFeats(model_subsetDF,catFeats,categorical_features_mask)\n",
    "    return processedModelFeatures\n",
    "catFeats=['phone_brand','device_model']\n",
    "categorical_features_mask=[False,False,False,False,False,True,True]\n",
    "modelFeats_trainDF=processModelFeatures(eventBasedFeats,catFeats,deviceEvntsBrnds_trainDF,categorical_features_mask)\n",
    "modelFeats_testDF=processModelFeatures(eventBasedFeats,catFeats,deviceEvntsBrnds_testDF,categorical_features_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 1563) (112071, 1658)\n",
      "[[ 0.          0.          0.00144613  0.10865743  0.42820583  0.09177323\n",
      "   0.22467937]\n",
      " [ 0.          0.          0.01232859  0.02876541  0.23580696  0.08166277\n",
      "   0.37801029]\n",
      " [ 0.          0.          0.00241022  0.          0.09032746  0.04788587\n",
      "   0.18452801]\n",
      " [ 0.          0.          0.01232859  0.02876541  0.23580696  0.08166277\n",
      "   0.37801029]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>num_of_evnts</th>\n",
       "      <th>avg_evnt_drtn</th>\n",
       "      <th>std_evnt_drtn</th>\n",
       "      <th>avgLongtdChgFrq</th>\n",
       "      <th>avgSqrdLongtdChgAmt</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7477216237379271436</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>F33-42</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.711114e+13</td>\n",
       "      <td>6.637354e+13</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>4084.852943</td>\n",
       "      <td>华为</td>\n",
       "      <td>荣耀6 plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2478205222798310601</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>F27-28</td>\n",
       "      <td>52.151315</td>\n",
       "      <td>2.412437e+13</td>\n",
       "      <td>1.116697e+14</td>\n",
       "      <td>0.236296</td>\n",
       "      <td>1081.402878</td>\n",
       "      <td>三星</td>\n",
       "      <td>Galaxy Note 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              device_id gender  age   group  num_of_evnts  avg_evnt_drtn  \\\n",
       "11  7477216237379271436      F   37  F33-42      7.000000   2.711114e+13   \n",
       "12  2478205222798310601      F   28  F27-28     52.151315   2.412437e+13   \n",
       "\n",
       "    std_evnt_drtn  avgLongtdChgFrq  avgSqrdLongtdChgAmt phone_brand  \\\n",
       "11   6.637354e+13         0.428571          4084.852943          华为   \n",
       "12   1.116697e+14         0.236296          1081.402878          三星   \n",
       "\n",
       "     device_model  \n",
       "11       荣耀6 plus  \n",
       "12  Galaxy Note 3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(modelFeats_trainDF.shape,modelFeats_testDF.shape)\n",
    "print(modelFeats_trainDF[11:15,1556:])\n",
    "deviceEvntsBrnds_trainDF[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2),min_df=0.0)\n",
    "device_brand_model_trainDF['brand_model'] = device_brand_model_trainDF['phone_brand'] + ' ' + device_brand_model_trainDF['device_model']\n",
    "device_brand_model_testDF['brand_model'] = device_brand_model_testDF['phone_brand'] + ' ' + device_brand_model_testDF['device_model']\n",
    "vect_matrix = vectorizer.fit_transform(device_brand_model_trainDF['brand_model'])\n",
    "test_vect_matrix = vectorizer.transform(device_brand_model_testDF['brand_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validateModel(X,y, model):\n",
    "    kf = KFold(X.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "    for itrain, itest in kf:\n",
    "        if type(X)==type(pd.DataFrame()):\n",
    "            train=X.ix[itrain]\n",
    "            test=X.ix[itest]\n",
    "        else:\n",
    "            train = X[itrain,:]\n",
    "            test = X[itest,:]\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        clf = model.fit(train,ytrain)\n",
    "        ypred = clf.predict_proba(test)\n",
    "        print(ypred.shape)\n",
    "        print(log_loss(ytest, ypred))\n",
    "        \n",
    "def getModelOutput(X,y,X2, model):\n",
    "    kf = KFold(X.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "    for itrain, itest in kf:\n",
    "        if type(X)==type(pd.DataFrame()):\n",
    "            train=X.ix[itrain]\n",
    "            test=X.ix[itest]\n",
    "        else:\n",
    "            train = X[itrain,:]\n",
    "            test = X[itest,:]\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        clf = model.fit(train,ytrain)\n",
    "        ypred = clf.predict_proba(X2)\n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm  import LinearSVC\n",
    "#class CalibModel(object):\n",
    "class CalibModel(object):\n",
    "    def __init__(self,clf):\n",
    "        #clf = MultinomialNB()\n",
    "        print(\"Obtained Classifier Instance \",clf)\n",
    "        self.clf = CalibratedClassifierCV(clf, cv=2, method='sigmoid')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eventsData_train_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e1e958051c55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#validateModel(vect_matrix, device_brand_model_trainDF['group'], CalibModel(MultinomialNB()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#validateModel(vect_matrix, phone_brand_master['group'], CalibModel(LinearSVC()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvalidateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meventsData_train_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meventsData_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCalibModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#from sklearn.ensemble import RandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(RandomForestClassifier()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eventsData_train_final' is not defined"
     ]
    }
   ],
   "source": [
    "#validateModel(vect_matrix, device_brand_model_trainDF['group'], CalibModel(MultinomialNB()))\n",
    "#validateModel(vect_matrix, phone_brand_master['group'], CalibModel(LinearSVC()))\n",
    "validateModel(eventsData_train_final,eventsData_train.group,CalibModel(GaussianNB()))\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(RandomForestClassifier()))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(DecisionTreeClassifier()))\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(AdaBoostClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#base_estimator_obj=DecisionTreeClassifier(min_samples_split=10000)\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], \n",
    "#              CalibModel(AdaBoostClassifier(base_estimator=base_estimator_obj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(LogisticRegression(C=0.1)))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(LogisticRegression(C=.2)))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(LogisticRegression(n_jobs=5,penalty='l1')))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(LogisticRegression(n_jobs=5,solver='newton-cg',C=0.2)))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(LogisticRegression(n_jobs=5,solver='newton-cg',C=0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Deep Learning : Keras Modelling\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1600, input_dim=1563, init='uniform', activation='relu'))\n",
    "model.add(Dense(1563, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ...,  6, 10,  7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetLabelEncoder=LabelEncoder()\n",
    "encodedTarget_train=targetLabelEncoder.fit_transform(device_brand_model_trainDF['group'])\n",
    "encodedTarget_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74645/74645 [==============================] - 965s - loss: -86.1852 - acc: 0.0561   \n",
      "Epoch 2/10\n",
      "74645/74645 [==============================] - 959s - loss: -86.1852 - acc: 0.0561   \n",
      "Epoch 3/10\n",
      "74645/74645 [==============================] - 963s - loss: -86.1852 - acc: 0.0561   \n",
      "Epoch 4/10\n",
      "74645/74645 [==============================] - 1051s - loss: -86.1852 - acc: 0.0561  \n",
      "Epoch 5/10\n",
      "74645/74645 [==============================] - 1296s - loss: -86.1852 - acc: 0.0561  \n",
      "Epoch 6/10\n",
      "74645/74645 [==============================] - 1621s - loss: -86.1852 - acc: 0.0561  \n",
      "Epoch 7/10\n",
      "74645/74645 [==============================] - 1676s - loss: -86.1852 - acc: 0.0561  \n",
      "Epoch 8/10\n",
      "74645/74645 [==============================] - 1677s - loss: -86.1852 - acc: 0.0561  \n",
      "Epoch 9/10\n",
      "74645/74645 [==============================] - 1675s - loss: -86.1852 - acc: 0.0561  \n",
      "Epoch 10/10\n",
      "74645/74645 [==============================] - 1674s - loss: -86.1852 - acc: 0.0561  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd918152b38>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(modelFeats_trainDF, encodedTarget_train, nb_epoch=10, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-53750b47e990>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictedProbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelFeats_trainDF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencodedTarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         '''\n\u001b[1;32m--> 735\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m             warnings.warn('Network returning invalid probability values. '\n",
      "\u001b[1;32m/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         return self._predict_loop(f, ins,\n\u001b[1;32m-> 1180\u001b[1;33m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m             \u001b[0mprogbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProgbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 869\u001b[1;33m         \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m         \u001b[0mindex_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_end\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mmake_batches\u001b[1;34m(size, batch_size)\u001b[0m\n\u001b[0;32m    279\u001b[0m     '''Returns a list of batch indices (tuples of indices).\n\u001b[0;32m    280\u001b[0m     '''\n\u001b[1;32m--> 281\u001b[1;33m     \u001b[0mnb_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m     return [(i * batch_size, min(size, (i + 1) * batch_size))\n\u001b[0;32m    283\u001b[0m             for i in range(0, nb_batch)]\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "predictedProbs=model.predict_proba(modelFeats_trainDF, encodedTarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
