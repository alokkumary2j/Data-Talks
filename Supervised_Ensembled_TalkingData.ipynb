{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imputeDFColsUsingMedian(dataFrame,cols):\n",
    "    for col in cols:\n",
    "        medianOfCol=np.nanmedian(dataFrame[col])\n",
    "        dataFrame[col].fillna(medianOfCol,inplace=True)\n",
    "def imputeDFColsUsingMean(dataFrame,cols):\n",
    "    for col in cols:\n",
    "        meanOfCol=np.nanmean(dataFrame[col])\n",
    "        dataFrame[col].fillna(meanOfCol,inplace=True)\n",
    "def scaleFeature(dataFrame,col):\n",
    "    maxVal=np.max(dataFrame[col])\n",
    "    minVal=np.min(dataFrame[col])\n",
    "    scaledDenom=maxVal-minVal\n",
    "    dataFrame[col]=(dataFrame[col]-minVal)/scaledDenom\n",
    "def labelEncodeFeats(dataFrame,listOfFeats):\n",
    "    for feat in listOfFeats:\n",
    "        labelEncoder=LabelEncoder()\n",
    "        encodedFeatValues=labelEncoder.fit_transform(dataFrame[feat])\n",
    "        dataFrame[feat]=encodedFeatValues\n",
    "def OneHotEncodeFeats(dataFrame,listOfFeats,ctgrcl_ftrs_msk):\n",
    "    labelEncodeFeats(dataFrame,listOfFeats)\n",
    "    oneHotEncoder=OneHotEncoder(categorical_features=ctgrcl_ftrs_msk,sparse=False)\n",
    "    oneHotEncodedFeats=oneHotEncoder.fit_transform(dataFrame)\n",
    "    return oneHotEncodedFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_events = pd.read_csv('../Data/app_events.csv')\n",
    "app_labels = pd.read_csv('../Data/app_labels.csv')\n",
    "events = pd.read_csv('../Data/events.csv')\n",
    "events.timestamp=events.timestamp.map(lambda x:pd.Timestamp(x).value)\n",
    "eventsGrpdByDeviceId=events.groupby('device_id')\n",
    "gender_age_train = pd.read_csv('../Data/gender_age_train.csv')\n",
    "gender_age_test = pd.read_csv('../Data/gender_age_test.csv')\n",
    "label_categories = pd.read_csv('../Data/label_categories.csv')\n",
    "phone_brand_device_model = pd.read_csv('../Data/phone_brand_device_model.csv',encoding='utf-8')\n",
    "phone_brand_device_model = phone_brand_device_model.drop_duplicates('device_id',keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joinBrandDeviceModel(deviceIDFrame,brandDeviceModelFrame):\n",
    "    mergedDF=deviceIDFrame.merge(brandDeviceModelFrame[['device_id','phone_brand','device_model']], \n",
    "                                 how='left',on='device_id')\n",
    "    mergedDF['phone_brand'].fillna('',inplace=True)\n",
    "    mergedDF['device_model'].fillna('',inplace=True)\n",
    "    return mergedDF\n",
    "device_brand_model_trainDF=joinBrandDeviceModel(gender_age_train,phone_brand_device_model)\n",
    "device_brand_model_testDF=joinBrandDeviceModel(gender_age_test,phone_brand_device_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avgEventDuration(listOfTimeStamps):\n",
    "    if(len(listOfTimeStamps)<1):\n",
    "        return 0\n",
    "    return (np.max(listOfTimeStamps)-np.min(listOfTimeStamps))/len(listOfTimeStamps)\n",
    "def stdEventDuration(listOfTimeStamps):\n",
    "    if(len(set(listOfTimeStamps))<=1):\n",
    "        return 0\n",
    "    return np.std(listOfTimeStamps)\n",
    "def avglongChangeFreq(listOfLongs):\n",
    "    if(len(listOfLongs)<1):\n",
    "        return 0\n",
    "    return len(set(listOfLongs))/float(len(listOfLongs))\n",
    "def avgSqrdlongChangeAmt(listOfLongs):\n",
    "    if(len(listOfLongs)<1):\n",
    "        return 0\n",
    "    return np.sum(np.diff(listOfLongs)**2)/float(len(listOfLongs))\n",
    "def computeEventBasedFeatures(eventsGrpdByDeviceId):\n",
    "    eventBasedAggregates=eventsGrpdByDeviceId.aggregate({'timestamp':[np.count_nonzero,avgEventDuration,\n",
    "                            stdEventDuration],'longitude':[avglongChangeFreq,avgSqrdlongChangeAmt]})\n",
    "    eventBasedAggregatesFeats=['num_of_evnts','avg_evnt_drtn','std_evnt_drtn','avgLongtdChgFrq','avgSqrdLongtdChgAmt']\n",
    "    eventBasedAggregates.columns=eventBasedAggregatesFeats\n",
    "    eventBasedAggregates['device_id']=eventBasedAggregates.index\n",
    "    return (eventBasedAggregates,eventBasedAggregatesFeats) \n",
    "def segregateFeaturesDataFrame(dataFrameToSegregate,colToSegOn,valueToSegOn,segOnNan=False):\n",
    "    if segOnNan:\n",
    "        exclFlag=np.isnan(dataFrameToSegregate[colToSegOn])\n",
    "    else:\n",
    "        exclFlag=dataFrameToSegregate[colToSegOn]==valueToSegOn\n",
    "    inclFlag=exclFlag==False\n",
    "    exclDF=dataFrameToSegregate[exclFlag]\n",
    "    incDF=dataFrameToSegregate[inclFlag]\n",
    "    return (incDF,exclDF,inclFlag,exclFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(eventBasedFeaturesDF,eventBasedFeats)=computeEventBasedFeatures(eventsGrpdByDeviceId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combineDeviceEventsBrandsFeatures(deviceDF,deviceEventsDF,deviceEventsFeats,deviceBrandsDF,shouldImpute=True):\n",
    "    device_events_brands =deviceDF.merge(deviceEventsDF, how='left',on='device_id')\n",
    "    if shouldImpute==True:\n",
    "        imputeDFColsUsingMean(device_events_brands,deviceEventsFeats)\n",
    "    device_events_brands=device_events_brands.merge(deviceBrandsDF[['phone_brand','device_model','device_id']], \n",
    "                                                  how='left',on='device_id')\n",
    "    return device_events_brands\n",
    "deviceEvntsBrnds_trainDF=combineDeviceEventsBrandsFeatures(gender_age_train,eventBasedFeaturesDF,\n",
    "                                                   eventBasedFeats,device_brand_model_trainDF,False)\n",
    "deviceEvntsBrnds_testDF=combineDeviceEventsBrandsFeatures(gender_age_test,eventBasedFeaturesDF,\n",
    "                                                   eventBasedFeats,device_brand_model_testDF,False)\n",
    "def getZeroIndexedTargetSeries(dataFrame,indexesToIncl,colName):\n",
    "    dataFrame=dataFrame[indexesToIncl]\n",
    "    targetSeries=dataFrame[colName].copy(deep=True)\n",
    "    n=targetSeries.shape[0]\n",
    "    targetSeries.index=np.arange(n)\n",
    "    return targetSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(deviceEvntsBrndsIncl_trainDF,deviceEvntsBrndsExcl_trainDF,inclTrainFlag,exclTrainFlag)=segregateFeaturesDataFrame(\n",
    "    deviceEvntsBrnds_trainDF,'num_of_evnts',0,True)\n",
    "(deviceEvntsBrndsIncl_testDF,deviceEvntsBrndsExcl_testDF,inclTestFlag,exclTestFlag)=segregateFeaturesDataFrame(\n",
    "    deviceEvntsBrnds_testDF,'num_of_evnts',0,True)\n",
    "device_brand_model_incl_trainTarget=getZeroIndexedTargetSeries(device_brand_model_trainDF,inclTrainFlag,'group')\n",
    "#device_brand_model_incl_testTarget=getZeroIndexedTargetSeries(device_brand_model_testDF,inclTestFlag,'group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def processModelFeatures(contFeats,catFeats,modelDF,categorical_features_mask):\n",
    "    contFeats=list(set(contFeats))\n",
    "    catFeats=list(set(catFeats))\n",
    "    modelFeatures=contFeats.copy()\n",
    "    modelFeatures.extend(catFeats)\n",
    "    model_subsetDF=modelDF[modelFeatures]\n",
    "    for contFeat in contFeats:\n",
    "        scaleFeature(model_subsetDF,contFeat)\n",
    "    processedModelFeatures=OneHotEncodeFeats(model_subsetDF,catFeats,categorical_features_mask)\n",
    "    return processedModelFeatures\n",
    "catFeats=['phone_brand','device_model']\n",
    "categorical_features_mask=[False,False,False,False,False,True,True]\n",
    "modelFeatsIncl_trainDF=processModelFeatures(eventBasedFeats,catFeats,deviceEvntsBrndsIncl_trainDF,categorical_features_mask)\n",
    "modelFeatsIncl_testDF=processModelFeatures(eventBasedFeats,catFeats,deviceEvntsBrndsIncl_testDF,categorical_features_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 1020) (35194, 1157)\n"
     ]
    }
   ],
   "source": [
    "print(modelFeatsIncl_trainDF.shape,modelFeatsIncl_testDF.shape)#See, Here Not All Models Captured During Training Phase\n",
    "#So Probably I can capture All Models Captured During Training-- \n",
    "#         If the new model not inside=> only use Model based out of Phone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2),min_df=0.0)\n",
    "device_brand_model_trainDF['brand_model'] = device_brand_model_trainDF['phone_brand'] + ' ' + device_brand_model_trainDF['device_model']\n",
    "device_brand_model_testDF['brand_model'] = device_brand_model_testDF['phone_brand'] + ' ' + device_brand_model_testDF['device_model']\n",
    "vect_matrix = vectorizer.fit_transform(device_brand_model_trainDF['brand_model'])\n",
    "test_vect_matrix = vectorizer.transform(device_brand_model_testDF['brand_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validateModel(X,y, model):\n",
    "    kf = KFold(X.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "    for itrain, itest in kf:\n",
    "        if type(X)==type(pd.DataFrame()):\n",
    "            train=X.ix[itrain]\n",
    "            test=X.ix[itest]\n",
    "        else:\n",
    "            train = X[itrain,:]\n",
    "            test = X[itest,:]\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        clf = model.fit(train,ytrain)\n",
    "        ypred = clf.predict_proba(test)\n",
    "        print(ypred.shape)\n",
    "        print(log_loss(ytest, ypred))\n",
    "        \n",
    "def getModelOutput(X,y,X2, model):\n",
    "    kf = KFold(X.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "    for itrain, itest in kf:\n",
    "        if type(X)==type(pd.DataFrame()):\n",
    "            train=X.ix[itrain]\n",
    "            test=X.ix[itest]\n",
    "        else:\n",
    "            train = X[itrain,:]\n",
    "            test = X[itest,:]\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        clf = model.fit(train,ytrain)\n",
    "        ypred = clf.predict_proba(X2)\n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm  import LinearSVC\n",
    "#class CalibModel(object):\n",
    "class CalibModel(object):\n",
    "    def __init__(self,clf):\n",
    "        #clf = MultinomialNB()\n",
    "        print(\"Obtained Classifier Instance \",clf)\n",
    "        self.clf = CalibratedClassifierCV(clf, cv=2, method='sigmoid')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Classifier Instance  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=1600,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=6,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "(4662, 12)\n",
      "2.37830472243\n",
      "(4662, 12)\n",
      "2.38019372487\n",
      "(4662, 12)\n",
      "2.3716000584\n",
      "(4662, 12)\n",
      "2.36886065791\n",
      "(4661, 12)\n",
      "2.37154242039\n"
     ]
    }
   ],
   "source": [
    "#validateModel(vect_matrix, device_brand_model_trainDF['group'], CalibModel(MultinomialNB()))\n",
    "#validateModel(vect_matrix, phone_brand_master['group'], CalibModel(LinearSVC()))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(GaussianNB()))\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "validateModel(modelFeatsIncl_trainDF, device_brand_model_incl_trainTarget, \n",
    "              CalibModel(RandomForestClassifier(min_samples_split=1600,n_jobs=6,criterion='entropy')))\n",
    "#validateModel(eventsData_train_final,eventsData_train.group,CalibModel(GaussianNB()))\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(RandomForestClassifier()))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(DecisionTreeClassifier()))\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(AdaBoostClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Classifier Instance  LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "(4662, 12)\n",
      "2.37281693665\n",
      "(4662, 12)\n",
      "2.37542059291\n",
      "(4662, 12)\n",
      "2.36903857821\n",
      "(4662, 12)\n",
      "2.3689221964\n",
      "(4661, 12)\n",
      "2.3697267725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "validateModel(modelFeatsIncl_trainDF, device_brand_model_incl_trainTarget, \n",
    "              CalibModel(LogisticRegression(C=.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Classifier Instance  LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "(4662, 12)\n",
      "2.37354226546\n",
      "(4662, 12)\n",
      "2.3760013225\n",
      "(4662, 12)\n",
      "2.36916845846\n",
      "(4662, 12)\n",
      "2.36911745916\n",
      "(4661, 12)\n",
      "2.36952981101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "validateModel(modelFeatsIncl_trainDF, device_brand_model_incl_trainTarget, \n",
    "              CalibModel(LogisticRegression(C=.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Classifier Instance  AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=1600, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "(4662, 12)\n",
      "2.40105301908\n",
      "(4662, 12)\n",
      "2.40750961304\n",
      "(4662, 12)\n",
      "2.39790409408\n",
      "(4662, 12)\n",
      "2.40107712408\n",
      "(4661, 12)\n",
      "2.39904907009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "validateModel(modelFeatsIncl_trainDF, device_brand_model_incl_trainTarget, \n",
    "              CalibModel(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(min_samples_split=1600))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Deep Learning : Keras Modelling\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1600, input_dim=1563, init='uniform', activation='relu'))\n",
    "model.add(Dense(1563, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ...,  6, 10,  7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetLabelEncoder=LabelEncoder()\n",
    "encodedTarget_train=targetLabelEncoder.fit_transform(device_brand_model_trainDF['group'])\n",
    "encodedTarget_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 8290/74645 [==>...........................] - ETA: 640s - loss: -86.3842 - acc: 0.0560"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(modelFeats_trainDF, encodedTarget_train, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74645, 1563)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelFeats_trainDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
