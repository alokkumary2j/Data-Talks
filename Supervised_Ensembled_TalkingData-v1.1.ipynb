{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imputeDFColsUsingMedian(dataFrame,cols):\n",
    "    for col in cols:\n",
    "        medianOfCol=np.nanmedian(dataFrame[col])\n",
    "        dataFrame[col].fillna(medianOfCol,inplace=True)\n",
    "def imputeDFColsUsingMean(dataFrame,cols):\n",
    "    for col in cols:\n",
    "        meanOfCol=np.nanmean(dataFrame[col])\n",
    "        dataFrame[col].fillna(meanOfCol,inplace=True)\n",
    "def scaleFeature(dataFrame,col):\n",
    "    maxVal=np.max(dataFrame[col])\n",
    "    minVal=np.min(dataFrame[col])\n",
    "    scaledDenom=maxVal-minVal\n",
    "    dataFrame[col]=(dataFrame[col]-minVal)/scaledDenom\n",
    "def labelEncodeFeats(dataFrame,listOfFeats):\n",
    "    for feat in listOfFeats:\n",
    "        labelEncoder=LabelEncoder()\n",
    "        encodedFeatValues=labelEncoder.fit_transform(dataFrame[feat])\n",
    "        dataFrame[feat]=encodedFeatValues\n",
    "def OneHotEncodeFeats(dataFrame,listOfFeats,ctgrcl_ftrs_msk):\n",
    "    labelEncodeFeats(dataFrame,listOfFeats)\n",
    "    oneHotEncoder=OneHotEncoder(categorical_features=ctgrcl_ftrs_msk,sparse=False)\n",
    "    oneHotEncodedFeats=oneHotEncoder.fit_transform(dataFrame)\n",
    "    return oneHotEncodedFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_events = pd.read_csv('../Data/app_events.csv')\n",
    "app_labels = pd.read_csv('../Data/app_labels.csv')\n",
    "events = pd.read_csv('../Data/events.csv')\n",
    "events.timestamp=events.timestamp.map(lambda x:pd.Timestamp(x).value)\n",
    "eventsGrpdByDeviceId=events.groupby('device_id')\n",
    "gender_age_train = pd.read_csv('../Data/gender_age_train.csv')\n",
    "gender_age_test = pd.read_csv('../Data/gender_age_test.csv')\n",
    "label_categories = pd.read_csv('../Data/label_categories.csv')\n",
    "phone_brand_device_model = pd.read_csv('../Data/phone_brand_device_model.csv',encoding='utf-8')\n",
    "phone_brand_device_model = phone_brand_device_model.drop_duplicates('device_id',keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joinBrandDeviceModel(deviceIDFrame,brandDeviceModelFrame):\n",
    "    mergedDF=deviceIDFrame.merge(brandDeviceModelFrame[['device_id','phone_brand','device_model']], \n",
    "                                 how='left',on='device_id')\n",
    "    mergedDF['phone_brand'].fillna('',inplace=True)\n",
    "    mergedDF['device_model'].fillna('',inplace=True)\n",
    "    return mergedDF\n",
    "device_brand_model_trainDF=joinBrandDeviceModel(gender_age_train,phone_brand_device_model)\n",
    "device_brand_model_testDF=joinBrandDeviceModel(gender_age_test,phone_brand_device_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avgEventDuration(listOfTimeStamps):\n",
    "    if(len(listOfTimeStamps)<1):\n",
    "        return 0\n",
    "    return (np.max(listOfTimeStamps)-np.min(listOfTimeStamps))/len(listOfTimeStamps)\n",
    "def stdEventDuration(listOfTimeStamps):\n",
    "    if(len(set(listOfTimeStamps))<=1):\n",
    "        return 0\n",
    "    return np.std(listOfTimeStamps)\n",
    "def avglongChangeFreq(listOfLongs):\n",
    "    if(len(listOfLongs)<1):\n",
    "        return 0\n",
    "    return len(set(listOfLongs))/float(len(listOfLongs))\n",
    "def avgSqrdlongChangeAmt(listOfLongs):\n",
    "    if(len(listOfLongs)<1):\n",
    "        return 0\n",
    "    return np.sum(np.diff(listOfLongs)**2)/float(len(listOfLongs))\n",
    "def computeEventBasedFeatures(eventsGrpdByDeviceId):\n",
    "    eventBasedAggregates=eventsGrpdByDeviceId.aggregate({'timestamp':[np.count_nonzero,avgEventDuration,\n",
    "                            stdEventDuration],'longitude':[avglongChangeFreq,avgSqrdlongChangeAmt]})\n",
    "    eventBasedAggregatesFeats=['num_of_evnts','avg_evnt_drtn','std_evnt_drtn','avgLongtdChgFrq','avgSqrdLongtdChgAmt']\n",
    "    eventBasedAggregates.columns=eventBasedAggregatesFeats\n",
    "    eventBasedAggregates['device_id']=eventBasedAggregates.index\n",
    "    return (eventBasedAggregates,eventBasedAggregatesFeats) \n",
    "def segregateFeaturesDataFrame(dataFrameToSegregate,colToSegOn,valueToSegOn,segOnNan=False):\n",
    "    if segOnNan:\n",
    "        exclFlag=np.isnan(dataFrameToSegregate[colToSegOn])\n",
    "    else:\n",
    "        exclFlag=dataFrameToSegregate[colToSegOn]==valueToSegOn\n",
    "    inclFlag=exclFlag==False\n",
    "    exclDF=dataFrameToSegregate[exclFlag]\n",
    "    incDF=dataFrameToSegregate[inclFlag]\n",
    "    return (incDF,exclDF,inclFlag,exclFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(eventBasedFeaturesDF,eventBasedFeats)=computeEventBasedFeatures(eventsGrpdByDeviceId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combineDeviceEventsBrandsFeatures(deviceDF,deviceEventsDF,deviceEventsFeats,deviceBrandsDF,shouldImpute=True):\n",
    "    device_events_brands =deviceDF.merge(deviceEventsDF, how='left',on='device_id')\n",
    "    if shouldImpute==True:\n",
    "        imputeDFColsUsingMean(device_events_brands,deviceEventsFeats)\n",
    "    device_events_brands=device_events_brands.merge(deviceBrandsDF[['phone_brand','device_model','device_id']], \n",
    "                                                  how='left',on='device_id')\n",
    "    return device_events_brands\n",
    "deviceEvntsBrnds_trainDF=combineDeviceEventsBrandsFeatures(gender_age_train,eventBasedFeaturesDF,\n",
    "                                                   eventBasedFeats,device_brand_model_trainDF,False)\n",
    "deviceEvntsBrnds_testDF=combineDeviceEventsBrandsFeatures(gender_age_test,eventBasedFeaturesDF,\n",
    "                                                   eventBasedFeats,device_brand_model_testDF,False)\n",
    "def getZeroIndexedTargetSeries(dataFrame,indexesToIncl,colName):\n",
    "    dataFrame=dataFrame[indexesToIncl]\n",
    "    targetSeries=dataFrame[colName].copy(deep=True)\n",
    "    n=targetSeries.shape[0]\n",
    "    targetSeries.index=np.arange(n)\n",
    "    return targetSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(deviceEvntsBrndsIncl_trainDF,deviceEvntsBrndsExcl_trainDF,inclTrainFlag,exclTrainFlag)=segregateFeaturesDataFrame(\n",
    "    deviceEvntsBrnds_trainDF,'num_of_evnts',0,True)\n",
    "(deviceEvntsBrndsIncl_testDF,deviceEvntsBrndsExcl_testDF,inclTestFlag,exclTestFlag)=segregateFeaturesDataFrame(\n",
    "    deviceEvntsBrnds_testDF,'num_of_evnts',0,True)\n",
    "device_brand_model_incl_trainTarget=getZeroIndexedTargetSeries(device_brand_model_trainDF,inclTrainFlag,'group')\n",
    "device_brand_model_excl_trainTarget=getZeroIndexedTargetSeries(device_brand_model_trainDF,exclTrainFlag,'group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51336"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exclTrainFlag[exclTrainFlag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def combineTextFeatures(dataFrame,textFeatures,newFeatureName):\n",
    "    dataFrame[newFeatureName]=dataFrame[textFeatures[0]]\n",
    "    n=len(textFeatures)\n",
    "    for i in np.arange(1,n):\n",
    "        dataFrame[newFeatureName]=dataFrame[newFeatureName]+' '+dataFrame[textFeatures[i]]\n",
    "def prepareTextFeature(trainDF,testDF,textFeatures,newFeatureName):\n",
    "    combineTextFeatures(trainDF,textFeatures,newFeatureName)\n",
    "    combineTextFeatures(testDF,textFeatures,newFeatureName)\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,2),min_df=0.0)\n",
    "    vect_matrix = vectorizer.fit_transform(trainDF[newFeatureName])\n",
    "    test_vect_matrix = vectorizer.transform(testDF[newFeatureName])\n",
    "    return (vect_matrix,test_vect_matrix)\n",
    "(textData_model_train,textData_model_test)=prepareTextFeature(device_brand_model_trainDF[exclTrainFlag],\n",
    "                   device_brand_model_testDF[exclTestFlag],['phone_brand','device_model'],'brand_model')\n",
    "#device_brand_model_trainDF['brand_model'] = device_brand_model_trainDF['phone_brand'] + ' ' +\n",
    "#device_brand_model_trainDF['device_model']\n",
    "#device_brand_model_testDF['brand_model'] = device_brand_model_testDF['phone_brand'] + ' ' + \n",
    "#device_brand_model_testDF['device_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/alokkumary2j/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def processModelFeatures(contFeats,catFeats,modelDF,categorical_features_mask):\n",
    "    contFeats=list(set(contFeats))\n",
    "    catFeats=list(set(catFeats))\n",
    "    modelFeatures=contFeats.copy()\n",
    "    modelFeatures.extend(catFeats)\n",
    "    model_subsetDF=modelDF[modelFeatures]\n",
    "    for contFeat in contFeats:\n",
    "        scaleFeature(model_subsetDF,contFeat)\n",
    "    processedModelFeatures=OneHotEncodeFeats(model_subsetDF,catFeats,categorical_features_mask)\n",
    "    return processedModelFeatures\n",
    "catFeats=['phone_brand','device_model']\n",
    "categorical_features_mask=[False,False,False,False,False,True,True]\n",
    "modelFeatsIncl_trainDF=processModelFeatures(eventBasedFeats,catFeats,deviceEvntsBrndsIncl_trainDF,categorical_features_mask)\n",
    "modelFeatsIncl_testDF=processModelFeatures(eventBasedFeats,catFeats,deviceEvntsBrndsIncl_testDF,categorical_features_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 1020) (35194, 1157)\n"
     ]
    }
   ],
   "source": [
    "print(modelFeatsIncl_trainDF.shape,modelFeatsIncl_testDF.shape)#See, Here Not All Models Captured During Training Phase\n",
    "#So Probably I can capture All Models Captured During Training-- \n",
    "#         If the new model not inside=> only use Model based out of Phone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 2799)\n",
      "(74645, 6) 23309 51336\n",
      "(112071, 3) 35194 76877\n"
     ]
    }
   ],
   "source": [
    "print(textData_model_train.shape)\n",
    "print(device_brand_model_trainDF.shape,len(inclTrainFlag[inclTrainFlag]),len(exclTrainFlag[exclTrainFlag]))\n",
    "print(device_brand_model_testDF.shape,len(inclTestFlag[inclTestFlag]),len(exclTestFlag[exclTestFlag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def obtainProbs(X,y,model):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "    clf=model.fit(X_train,y_train)\n",
    "    y_pred=clf.predict_proba(X_test)\n",
    "    return (y_pred,y_test)\n",
    "def validateModel(X,y, model):\n",
    "    kf = KFold(X.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "    for itrain, itest in kf:\n",
    "        if type(X)==type(pd.DataFrame()):\n",
    "            train=X.ix[itrain]\n",
    "            test=X.ix[itest]\n",
    "        else:\n",
    "            train = X[itrain,:]\n",
    "            test = X[itest,:]\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        clf = model.fit(train,ytrain)\n",
    "        ypred = clf.predict_proba(test)\n",
    "        print(ypred.shape)\n",
    "        print(log_loss(ytest, ypred))\n",
    "        \n",
    "def getModelOutput(X,y,X2, model):\n",
    "    kf = KFold(X.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "    for itrain, itest in kf:\n",
    "        if type(X)==type(pd.DataFrame()):\n",
    "            train=X.ix[itrain]\n",
    "            test=X.ix[itest]\n",
    "        else:\n",
    "            train = X[itrain,:]\n",
    "            test = X[itest,:]\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        clf = model.fit(train,ytrain)\n",
    "        ypred = clf.predict_proba(X2)\n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm  import LinearSVC\n",
    "#class CalibModel(object):\n",
    "class CalibModel(object):\n",
    "    def __init__(self,clf):\n",
    "        #clf = MultinomialNB()\n",
    "        print(\"Obtained Classifier Instance \",clf)\n",
    "        self.clf = CalibratedClassifierCV(clf, cv=2, method='sigmoid')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Classifier Instance  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=1600,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=6,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "2.3750257931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, numpy.ndarray)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(y_pred,y_test)=obtainProbs(vect_matrix, device_brand_model_trainDF['group'], CalibModel(MultinomialNB()))\n",
    "#print(y_pred.shape,y_test.shape\n",
    "#validateModel(vect_matrix, phone_brand_master['group'], CalibModel(LinearSVC()))\n",
    "#validateModel(modelFeats_trainDF, device_brand_model_trainDF['group'], CalibModel(GaussianNB()))\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "(y_pred,y_test)=obtainProbs(modelFeatsIncl_trainDF, device_brand_model_incl_trainTarget, \n",
    "              CalibModel(RandomForestClassifier(min_samples_split=1600,n_jobs=6,criterion='entropy')))\n",
    "#y_pred.shape,y_test.shape\n",
    "print(log_loss(y_test,y_pred))#2.3725889\n",
    "type(y_test),type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Classifier Instance  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "2.40455445142\n"
     ]
    }
   ],
   "source": [
    "(y_pred_text,y_test_text)=obtainProbs(textData_model_train, device_brand_model_excl_trainTarget, \n",
    "                                      CalibModel(MultinomialNB()))\n",
    "print(log_loss(y_test_text,y_pred_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3953335035056385"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_ensembled=y_test.append(y_test_text)\n",
    "y_pred_ensembled=np.concatenate((y_pred,y_pred_text))\n",
    "log_loss(y_test_ensembled,y_pred_ensembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Deep Learning : Keras Modelling\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1600, input_dim=1020, init='uniform', activation='relu'))\n",
    "model.add(Dense(1563, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  4, 10, ...,  5, 10,  7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetLabelEncoder=LabelEncoder()\n",
    "encodedTarget_train=targetLabelEncoder.fit_transform(device_brand_model_incl_trainTarget)\n",
    "encodedTarget_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16316/16316 [==============================] - 32s - loss: -90.4415 - acc: 0.0484    \n",
      "Epoch 2/2\n",
      "16316/16316 [==============================] - 32s - loss: -90.4415 - acc: 0.0484    \n",
      "6976/6993 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.568849434219324"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dl,X_test_dl,y_train_dl,y_test_dl=train_test_split(modelFeatsIncl_trainDF,encodedTarget_train,test_size=0.3)\n",
    "#clf_dl=model.fit(X_train_dl,y_train_dl)\n",
    "clf_dl=model.fit(X_train_dl,y_train_dl,nb_epoch=2,batch_size=100)\n",
    "y_pred_dl=clf_dl.model.predict_proba(X_test_dl)\n",
    "log_loss(y_pred_dl,y_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16316/16316 [==============================] - 7s - loss: -90.1386 - acc: 0.0492     \n",
      "Epoch 2/2\n",
      "16316/16316 [==============================] - 7s - loss: -90.1386 - acc: 0.0492     \n",
      "6993/6993 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.445370326567598"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dl,X_test_dl,y_train_dl,y_test_dl=train_test_split(modelFeatsIncl_trainDF,encodedTarget_train,test_size=0.3)\n",
    "#clf_dl=model.fit(X_train_dl,y_train_dl)\n",
    "clf_dl=model.fit(X_train_dl,y_train_dl,nb_epoch=2,batch_size=1000)\n",
    "y_pred_dl=clf_dl.model.predict_proba(X_test_dl)\n",
    "log_loss(y_pred_dl,y_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16316/16316 [==============================] - 4s - loss: -90.0555 - acc: 0.0487     \n",
      "Epoch 2/2\n",
      "16316/16316 [==============================] - 4s - loss: -90.0555 - acc: 0.0487     \n",
      "6993/6993 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.514518626852563"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dl,X_test_dl,y_train_dl,y_test_dl=train_test_split(modelFeatsIncl_trainDF,encodedTarget_train,test_size=0.3)\n",
    "#clf_dl=model.fit(X_train_dl,y_train_dl)\n",
    "clf_dl=model.fit(X_train_dl,y_train_dl,nb_epoch=2,batch_size=10000)\n",
    "y_pred_dl=clf_dl.model.predict_proba(X_test_dl)\n",
    "log_loss(y_pred_dl,y_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 2/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 3/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 4/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 5/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 6/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 7/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 8/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 9/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 10/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 11/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 12/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 13/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 14/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 15/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 16/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 17/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 18/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 19/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "Epoch 20/20\n",
      "16316/16316 [==============================] - 4s - loss: -90.1913 - acc: 0.0504     \n",
      "6993/6993 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.475005312404008"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dl,X_test_dl,y_train_dl,y_test_dl=train_test_split(modelFeatsIncl_trainDF,encodedTarget_train,test_size=0.3)\n",
    "#clf_dl=model.fit(X_train_dl,y_train_dl)\n",
    "clf_dl=model.fit(X_train_dl,y_train_dl,nb_epoch=20,batch_size=10000)\n",
    "y_pred_dl=clf_dl.model.predict_proba(X_test_dl)\n",
    "log_loss(y_pred_dl,y_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 2/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 3/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 4/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 5/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 6/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 7/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 8/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 9/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 10/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 11/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 12/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 13/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 14/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 15/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 16/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 17/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 18/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 19/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "Epoch 20/20\n",
      "16316/16316 [==============================] - 5s - loss: -90.3184 - acc: 0.0481     \n",
      "6993/6993 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.583666927137536"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dl,X_test_dl,y_train_dl,y_test_dl=train_test_split(modelFeatsIncl_trainDF,encodedTarget_train,test_size=0.3)\n",
    "#clf_dl=model.fit(X_train_dl,y_train_dl)\n",
    "clf_dl=model.fit(X_train_dl,y_train_dl,nb_epoch=20,batch_size=5000)\n",
    "y_pred_dl=clf_dl.model.predict_proba(X_test_dl)\n",
    "log_loss(y_pred_dl,y_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
